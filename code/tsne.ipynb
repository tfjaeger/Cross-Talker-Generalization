{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE (t-distributed stochastic neighbor embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-SNE is a dimensionality reduction and data visualization method. Its main purpose is to embed data from high-dimensional space into low-dimensional space (usually two or three dimensions) to visually display the structure and similarity relationships of the data in the lower-dimensional space. This method was proposed by [Maaten and Hinton, 2008](!https://www.jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf) and is commonly used for visualization tasks in machine learning. A clear video explaination could be found [here](!https://www.youtube.com/watch?v=NEaUSP4YerM&t=603s).\n",
    "\n",
    "The main steps are as follows:\n",
    "1. Computing similarity in high-dimensional space: A **Gaussian distribution** is used to measure how similar each point is to its neighboring points in the high-dimensional space.\n",
    "2. Creating an embedding in low-dimensional space: The data is randomly initialized in low-dimensional space (typically two or three dimensions). Then, a **t-distribution** is applied to calculate the similarity between points in the lower-dimensional space.\n",
    "3. Optimization: The algorithm minimizes the Kullback-Leibler **(KL) divergence** (relative entropy loss) between the similarity distributions in the high-dimensional and low-dimensional spaces using **gradient descent**, gradually improving the low-dimensional representation to best reflect the high-dimensional relationships.\n",
    "\n",
    "Detailed explanation follows:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Similarity in high-dimensional space\n",
    "t-SNE begins by calculating the **similarities** between every pair of data points in the high-dimensional space. These similarities measure how close two points are to each other and are represented using **conditional probabilities**.\n",
    "\n",
    "### Similarity Calculation in High-Dimensional Space:\n",
    "For a given data point  and $x_j$, t-SNE computes the conditional probability $p_{j|i}$ using a Gaussian distribution:\n",
    "\n",
    "$$\n",
    "p_{j|i} = \\frac{\\exp\\left(- \\frac{||x_i - x_j||^2}{2\\sigma_i^2}\\right)}{\\sum_{k \\neq i} \\exp\\left(- \\frac{||x_i - x_k||^2}{2\\sigma_i^2}\\right)}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $||x_i - x_j||^2$ is the squared Euclidean distance between points $x_i$ and $x_j$.\n",
    "- $\\sigma_i$ is a local scaling parameter for point $x_i$, controlling the width of the neighborhood around the point.\n",
    "\n",
    "This probability $p_{j|i}$ reflects how likely it is that point $x_i$ would choose $x_j$ as a neighbor.\n",
    "\n",
    "To make the similarities symmetric, the following formula is used:\n",
    "$$\n",
    "p_{ij} = \\frac{p_{j|i} + p_{i|j}}{2N}\n",
    "$$\n",
    "Where $N$ is the total number of data points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Similarities in Low-Dimensional Space\n",
    "\n",
    "t-SNE maps the high-dimensional data to a low-dimensional space (e.g., 2D or 3D) and uses the **t-distribution** (instead of a Gaussian distribution) to compute pairwise similarities in the low-dimensional space. The t-distributionâ€™s heavier tails help to avoid \"crowding\" effects in low dimensions.\n",
    "\n",
    "### Similarity Calculation in Low-Dimensional Space:\n",
    "In low-dimensional space, for embedded points $y_i$ and $y_j$, t-SNE computes the similarity $q_{ij}$ using the t-distribution:\n",
    "\n",
    "$$\n",
    "q_{ij} = \\frac{(1 + ||y_i - y_j||^2)^{-1}}{\\sum_{k \\neq l}(1 + ||y_k - y_l||^2)^{-1}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $||y_i - y_j||^2$ is the squared Euclidean distance between points $y_i$ and $y_j$ in the low-dimensional space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Define the Loss Function (KL Divergence)\n",
    "\n",
    "t-SNE aims to find a low-dimensional embedding where the similarity distributions in high-dimensional and low-dimensional spaces are as close as possible. This is done by minimizing the **Kullback-Leibler (KL) divergence** between the two distributions.\n",
    "\n",
    "### KL Divergence:\n",
    "The KL divergence between the high-dimensional distribution $P$ and the low-dimensional distribution $Q$ is defined as:\n",
    "\n",
    "$$\n",
    "C = KL(P||Q) = \\sum_{i} \\sum_{j} p_{ij} \\log \\left( \\frac{p_{ij}}{q_{ij}} \\right)\n",
    "$$\n",
    "\n",
    "This loss function penalizes differences between the high-dimensional similarities $p_{ij}$ and the low-dimensional similarities $q_{ij}$.\n",
    "\n",
    "- When $p_{ij}$ is large and $q_{ij}$ is small, the KL divergence increases, indicating that two similar points in high-dimensional space are far apart in low-dimensional space.\n",
    "- Conversely, when $q_{ij}$ is large but $p_{ij}$ is small, this case is less penalized, allowing non-similar points to be close in low-dimensional space.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Optimize the Embedding Using Gradient Descent\n",
    "\n",
    "To minimize the KL divergence, t-SNE uses gradient descent. It iteratively adjusts the positions of the points $y_i$ in the low-dimensional space to reduce the loss.\n",
    "\n",
    "The gradient of the loss function can be computed as:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial C}{\\partial y_i} = S \\sum_j (p_{ij} - q_{ij})(y_i - y_j)(1 + ||y_i - y_j||^2)^{-1}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $p_{ij} - q_{ij}$ is the difference between the high-dimensional and low-dimensional similarities.\n",
    "\n",
    "The embedding is adjusted iteratively until the loss converges or a maximum number of iterations is reached.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "After multiple iterations, t-SNE outputs the low-dimensional embedding, where the points are positioned such that the local structure (neighborhood relationships) of the high-dimensional data is preserved as much as possible. The final result is typically used for visualization."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesPCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
